#!/usr/bin/env python3
"""
ChatGPT ìŠ¤íƒ€ì¼ í„°ë¯¸ë„ UI
Rich ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ ì¸í„°ë™í‹°ë¸Œ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
"""

import requests
import json
import time
from datetime import datetime
from typing import Optional, List, Dict

from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.live import Live
from rich.spinner import Spinner
from rich.table import Table
from rich.prompt import Prompt
from rich.layout import Layout
from rich.text import Text
from rich import box

# Ollama API ì„¤ì •
OLLAMA_URL = "http://localhost:11434"
MODEL_NAME = "llama2:7b-chat-q4_0"

console = Console()


class ChatSession:
    """ì±„íŒ… ì„¸ì…˜ ê´€ë¦¬"""

    def __init__(self):
        self.history: List[Dict[str, str]] = []
        self.start_time = datetime.now()

    def add_message(self, role: str, content: str, tokens: Optional[int] = None):
        """ë©”ì‹œì§€ ì¶”ê°€"""
        self.history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now(),
            "tokens": tokens
        })

    def get_history_text(self) -> str:
        """íˆìŠ¤í† ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if not self.history:
            return "[dim]ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.[/dim]"

        text = ""
        for msg in self.history[-5:]:  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
            time_str = msg["timestamp"].strftime("%H:%M:%S")
            role_emoji = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–"
            text += f"[dim]{time_str}[/dim] {role_emoji} "
            if msg["role"] == "user":
                text += f"[cyan]{msg['content'][:50]}...[/cyan]\n" if len(msg['content']) > 50 else f"[cyan]{msg['content']}[/cyan]\n"
            else:
                text += f"[green]{msg['content'][:50]}...[/green]\n" if len(msg['content']) > 50 else f"[green]{msg['content']}[/green]\n"

        return text

    def get_stats(self) -> Table:
        """ì„¸ì…˜ í†µê³„"""
        table = Table(box=box.SIMPLE, show_header=False, padding=(0, 1))
        table.add_column(style="cyan")
        table.add_column(style="green")

        duration = datetime.now() - self.start_time
        total_tokens = sum(msg.get("tokens", 0) for msg in self.history)

        table.add_row("ğŸ’¬ ì´ ë©”ì‹œì§€", str(len(self.history)))
        table.add_row("â±ï¸  ì„¸ì…˜ ì‹œê°„", f"{duration.seconds // 60}ë¶„ {duration.seconds % 60}ì´ˆ")
        table.add_row("ğŸ¯ í† í° ìˆ˜", str(total_tokens) if total_tokens > 0 else "N/A")

        return table


def check_ollama_connection() -> bool:
    """Ollama ì„œë²„ ì—°ê²° í™•ì¸"""
    try:
        response = requests.get(f"{OLLAMA_URL}/api/tags", timeout=5)
        return response.status_code == 200
    except:
        return False


def stream_response(prompt: str) -> tuple[str, Dict]:
    """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸°"""
    url = f"{OLLAMA_URL}/api/generate"

    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": True
    }

    full_response = ""
    metadata = {}

    try:
        response = requests.post(url, json=payload, stream=True, timeout=120)

        if response.status_code == 200:
            for line in response.iter_lines():
                if line:
                    chunk = json.loads(line)
                    if 'response' in chunk:
                        text = chunk['response']
                        full_response += text
                        yield text

                    if chunk.get('done', False):
                        metadata = {
                            'eval_count': chunk.get('eval_count'),
                            'total_duration': chunk.get('total_duration'),
                        }
                        break
        else:
            yield f"[red]Error: {response.status_code}[/red]"

    except Exception as e:
        yield f"[red]Exception: {str(e)}[/red]"

    return full_response, metadata


def display_welcome():
    """í™˜ì˜ ë©”ì‹œì§€"""
    welcome_text = """
# ğŸ¤– LLM Chat Interface

**Ollama** ê¸°ë°˜ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.

### ëª…ë ¹ì–´
- `/help` - ë„ì›€ë§ í‘œì‹œ
- `/history` - ëŒ€í™” ê¸°ë¡ ë³´ê¸°
- `/clear` - í™”ë©´ ì§€ìš°ê¸°
- `/stats` - ì„¸ì…˜ í†µê³„
- `/quit` ë˜ëŠ” `/exit` - ì¢…ë£Œ

ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!
"""
    console.print(Panel(Markdown(welcome_text), border_style="blue", title="Welcome"))


def display_thinking():
    """ìƒê° ì¤‘ í‘œì‹œ"""
    return Spinner("dots", text="[yellow]ìƒê°í•˜ëŠ” ì¤‘...[/yellow]", style="yellow")


def display_user_message(message: str):
    """ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ"""
    panel = Panel(
        message,
        title="[cyan]ğŸ‘¤ You[/cyan]",
        border_style="cyan",
        box=box.ROUNDED,
        padding=(1, 2)
    )
    console.print(panel)


def display_assistant_message(message: str):
    """ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ í‘œì‹œ (ë§ˆí¬ë‹¤ìš´ ë Œë”ë§)"""
    # ë©”ì‹œì§€ê°€ ì½”ë“œë¥¼ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë Œë”ë§
    panel = Panel(
        Markdown(message),
        title="[green]ğŸ¤– Assistant[/green]",
        border_style="green",
        box=box.ROUNDED,
        padding=(1, 2)
    )
    console.print(panel)


def display_streaming_message(prompt: str):
    """ìŠ¤íŠ¸ë¦¬ë° ë©”ì‹œì§€ í‘œì‹œ"""
    full_text = ""

    with Live(
        Panel(
            display_thinking(),
            title="[green]ğŸ¤– Assistant[/green]",
            border_style="green",
            box=box.ROUNDED
        ),
        refresh_per_second=10,
        console=console
    ) as live:

        for chunk in stream_response(prompt):
            if isinstance(chunk, str) and not chunk.startswith("[red]"):
                full_text += chunk
                # ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                live.update(
                    Panel(
                        full_text,
                        title="[green]ğŸ¤– Assistant[/green]",
                        border_style="green",
                        box=box.ROUNDED,
                        padding=(1, 2)
                    )
                )
            else:
                # ì—ëŸ¬ ë©”ì‹œì§€
                live.update(
                    Panel(
                        chunk,
                        title="[red]âŒ Error[/red]",
                        border_style="red",
                        box=box.ROUNDED
                    )
                )
                return None

    return full_text


def handle_command(command: str, session: ChatSession) -> bool:
    """ëª…ë ¹ì–´ ì²˜ë¦¬ (True: ê³„ì†, False: ì¢…ë£Œ)"""
    command = command.lower().strip()

    if command in ["/quit", "/exit", "/q"]:
        console.print("\n[yellow]ğŸ‘‹ ì„¸ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.[/yellow]\n")
        return False

    elif command == "/help":
        display_welcome()

    elif command == "/history":
        console.print(Panel(
            session.get_history_text(),
            title="ğŸ“œ ëŒ€í™” ê¸°ë¡ (ìµœê·¼ 5ê°œ)",
            border_style="blue"
        ))

    elif command == "/clear":
        console.clear()
        display_welcome()

    elif command == "/stats":
        console.print(Panel(
            session.get_stats(),
            title="ğŸ“Š ì„¸ì…˜ í†µê³„",
            border_style="magenta"
        ))

    else:
        console.print(f"[red]ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {command}[/red]")
        console.print("[dim]ë„ì›€ë§: /help[/dim]")

    return True


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    console.clear()

    # ì—°ê²° í™•ì¸
    with console.status("[yellow]Ollama ì„œë²„ ì—°ê²° í™•ì¸ ì¤‘...[/yellow]"):
        if not check_ollama_connection():
            console.print(Panel(
                "[red]âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.[/red]\n\n"
                "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”:\n"
                "[cyan]docker-compose up -d[/cyan]",
                title="Connection Error",
                border_style="red"
            ))
            return

    console.print("[green]âœ“[/green] Ollama ì„œë²„ ì—°ê²°ë¨\n")

    # í™˜ì˜ ë©”ì‹œì§€
    display_welcome()

    # ì„¸ì…˜ ì‹œì‘
    session = ChatSession()

    try:
        while True:
            # ì‚¬ìš©ì ì…ë ¥
            console.print()  # ë¹ˆ ì¤„
            user_input = Prompt.ask(
                "[bold cyan]You[/bold cyan]",
                default=""
            ).strip()

            if not user_input:
                continue

            # ëª…ë ¹ì–´ ì²˜ë¦¬
            if user_input.startswith("/"):
                if not handle_command(user_input, session):
                    break
                continue

            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
            display_user_message(user_input)
            session.add_message("user", user_input)

            # AI ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)
            console.print()  # ë¹ˆ ì¤„
            start_time = time.time()
            response = display_streaming_message(user_input)
            elapsed = time.time() - start_time

            if response:
                session.add_message("assistant", response)

                # ì„±ëŠ¥ ë©”íŠ¸ë¦­ í‘œì‹œ
                console.print(f"\n[dim]â±ï¸  {elapsed:.2f}ì´ˆ[/dim]")

    except KeyboardInterrupt:
        console.print("\n\n[yellow]ğŸ‘‹ Ctrl+Cë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.[/yellow]\n")
    except Exception as e:
        console.print(f"\n[red]ì˜¤ë¥˜ ë°œìƒ: {str(e)}[/red]\n")


if __name__ == "__main__":
    main()
