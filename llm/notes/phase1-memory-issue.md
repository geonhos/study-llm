# Phase 1: 메모리 부족 문제

**날짜**: 2025-12-02

## 문제
```
Error: model requires more system memory (5.5 GiB) than is available (5.2 GiB)
```

## 핵심
- Llama 2 7B 파일 크기: 3.8 GB
- 실행 시 필요 메모리: 5.5 GB (약 1.5배)
- 사용 가능 메모리: 5.2 GB
- **결과**: 실행 불가

## 왜?
- 모델 가중치 로딩
- 추론 계산 버퍼
- KV 캐시

## 프로덕션 영향
- 7B 모델: 최소 8GB RAM 필요 (권장 16GB)
- 13B: 16-32GB
- 70B: 80GB+ 또는 A100 GPU
- **동시 사용자 처리 = 메모리 배수 증가**

## 해결
1. 더 작은 모델 (TinyLlama)
2. 양자화 모델 (4-bit)
3. 메모리 증설

## 교훈
> LLM은 "일단 돌려보자"가 불가능하다. 초기부터 인프라 설계 필수.
