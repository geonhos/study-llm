# Phase 2: Chain of Thought 테스트 결과

**날짜**: 2025-12-02
**모델**: llama2:7b-chat-q4_0 (4-bit 양자화)
**테스트**: 직접 질문 vs Chain of Thought 비교

## 테스트 문제

사과 재고 계산 문제 (한국어)
- 초기: 50개
- 판매: 20개
- 입고: 30개
- 판매: 15개
- 개당 가격: 1,200원
- **정답**: 45개 × 1,200원 = 54,000원

## 결과 비교

### Test 1: 직접 질문
- **소요 시간**: 31.19초
- **답변**: "1,650원입니다"
- **정확도**: ❌ 오답

### Test 2: Chain of Thought
- **소요 시간**: 100.86초 (1분 40초)
- **답변**: 단계별 계산 제시 후 "54,640원"
- **정확도**: ❌ 오답 (하지만 추론 과정 제시)
- **속도**: 직접 질문 대비 3.2배 느림

## 핵심 발견

### 1. 성능 vs 품질 트레이드오프
- CoT는 3.2배 느리지만 추론 과정을 보여줌
- 직접 질문은 빠르지만 검증 불가능한 답변 제공

### 2. 언어 처리 문제
- **프롬프트**: 한국어
- **직접 질문 응답**: 한국어
- **CoT 응답**: 영어로 전환
- **이유**: CoT 패턴이 주로 영어 데이터로 학습됨

### 3. 정확도 문제
- 두 방식 모두 오답 생성
- CoT도 계산 오류 발생 (54,640원 vs 정답 54,000원)
- 단순 산술 문제임에도 신뢰성 부족

## 프로덕션 영향

- **응답 시간**: CoT 사용 시 사용자 대기 시간 급증
- **언어 일관성**: 다국어 서비스에서 예측 불가능한 언어 전환
- **신뢰성**: 추론 과정을 보여줘도 결과가 틀릴 수 있음
- **비용**: 토큰 소비량 증가 (긴 응답)

## 교훈

> Chain of Thought는 추론 과정을 투명하게 만들지만, 응답 시간과 정확도를 보장하지는 않는다.
